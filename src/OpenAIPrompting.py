from openai import OpenAI
    
# gets API key from private file
with open('C:/Users/conno/IMCATestProject/IMCA-AI-Project/misc/Key.txt', 'r', encoding='utf-8') as file:
    key = file.read().rstrip()
    
client = OpenAI(api_key= key)

def get_text_query(request:str) -> str:

    MODEL = "gpt-3.5-turbo"

    # TEXT BASED INPUT/RESPONSE
    response = client.chat.completions.create(
        model = MODEL,
        temperature = 0.2,
        max_tokens = 500,
        messages = [
            {"role": "system", "content": "You are an assistant that provides information about a museum's artwork via a list of classifications"},
            {"role": "user", "content": request}
        ]
    )

    # print("Response: " + response.choices[0].message.content)
    return response.choices[0].message.content

#IMAGE INPUT/RESPONSE
def get_image_query(request:str, base64_image:str) -> str:
    """Completes a GPT4o Query with the specified request string and image url string
        Returns a string containing the AI response"""
    
    #ex: image_url = "https://wikipedia.org/xyz"
    response = client.chat.completions.create(
        model = "gpt-4o",
        messages = [
            {"role": "system", "content": "You are an assistant that provides information about a museum's artwork via providing a list of single-word classifications"},
            {"role": "user", "content": [
                {"type": "text", "text": request},
                {"type": "image_url", 
                "image_url": {"url": f"data:image/jpeg;base64,{base64_image}",
                "detail": "low"}
                }
            ]}
        ],
        max_tokens = 300,
    )

    return response.choices[0].message.content # gives just the text generated by the prompt

    # print("Image Response: " + response.choices[0].message.content)

# # assistants allow for continous threads thus saving tokens
# class ClassificationThread:
#     """Object representing one thread of images from which the AI will provide a list of classifications"""
#     def __init__(self):
#         # initialize thread
#         self.thread = client.beta.threads.create()
        
#         #initialize assistant
#         self.assistant = client.beta.assistants.create(
#             name="Image Recognizer",
#             instructions="You are an assistant that provides information about a museum's artwork via providing a list of single-word classifications in response to image input",
#             tools=[{"type": "file_search"}],
#             model="gpt-4o"
#         )
        
#         self.threadID = self.thread.id
#         self.assistantID = self.assistant.id
        
#     def store_vectors(self, image_paths):
#         """Stores all the images in a vector using openai's file_search tool
#             Ultimately allows for my files to be used per assistant instead of the default 20 files"""
#         vector_store = client.beta.vector_stores.create(name="Museum Collection")
        
#         file_streams = [open(path, "rb") for path in image_paths]
        
#         file_batch = client.beta.vector_stores.file_batches.upload_and_poll(
#             vector_store_id=vector_store.id, file_streams
#         )
        
#     def upload_image(self, image_path):
#         '''Upload an image so that it can be used in a prompt
#             Returns the file object'''
#         file = client.files.create(
#             file=open(image_path, "rb"),
#             purpose="vision"
#         )
#         return file
    
#     def store_images(self, folder_path):
#         """Takes in the folder path and then uploads the image files to openAI and then appends file_id to dictionary
#             Args: directory of images
#             Returns: list of file objects"""
#         images = []
#         for file in os.listdir(folder_path):
#             file_id = self.upload_image(file)
#             images.append(file_id)
            
#         return images
            
        
        
#     def send_message(self, request:str, file:str)->str:
#         '''Adds a single message to the thread
#             Args:
#                 request: prompt 
#                 file: file_id of the image file
                
#             Returns: the text string generated by the prompt'''
#         response = client.beta.threads.messages.create(
#             thread_id = self.threadID,
#             role="user",
#             content=[
#             {
#             "type": "text",
#             "text": request
#             },
#             {
#             "type": "image_file",
#             "image_file": {
#                 "file_id": file,
#                 "purpose": "vision"
#             }
#         }
            
#         ]
#             # content = "Given the following image data, please check if the image contains any of the following keywords: people, trees, cat, dog, bridge, body of water, abstract"
#         )
        
#         return response.choices[0].message.content # gives just the text generated by the prompt
        
#     def run_assistant(self)->str:
#         '''Runs the thread retrieving all messages within the thread
#             Returns the list of messages'''
#         run = client.beta.threads.runs.create(
#             thread_id=self.threadID,
#             assistant_id=self.assistantID
#         )
        
#         run = client.beta.threads.runs.retrieve(
#             thread_id=self.threadID,
#             run_id=run.id
#         )
#         messages = client.beta.threads.messages.list(
#             thread_id = self.threadID
#         )
        
#         # returns all the messages in thread
#         return messages
